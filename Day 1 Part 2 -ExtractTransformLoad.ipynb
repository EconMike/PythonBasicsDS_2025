{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68b08f7",
   "metadata": {},
   "source": [
    "## Extract Tranform  Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e28d7",
   "metadata": {},
   "source": [
    "ETL, which stands for Extract, Transform, Load, is a crucial process in data management. It involves retrieving data from various sources, modifying it to fit business needs or target system requirements, and then loading it into a central location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('PRAC_DATA.csv')\n",
    "#pull up the first five observations\n",
    "df.head()\n",
    "#pull up the info on the table\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261b076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9513756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_excel('PRAC_DATA2.xlsx')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a specific worksheet in the excel file\n",
    "import pandas as pd\n",
    "xl = pd.ExcelFile('PRAC_DATA2.xlsx')\n",
    "xl.sheet_names\n",
    "df = xl.parse(\"Sheet1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile    # Import zipfile\n",
    "\n",
    "\n",
    "file = 'Testzip2.zip'          # Full path to the zip file, or simply the file name \n",
    "                               # if the file is in your current working directory\n",
    "zip_file = ZipFile(file, 'r')  # Read zipfile and extract contents\n",
    "zip_file.printdir()            # List files in the zip files\n",
    "zip_file.extractall()          # Extract files in the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08847b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xl = pd.ExcelFile('PRAC_DATA7.xlsx')\n",
    "xl.sheet_names\n",
    "df = xl.parse(\"Sheet1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open('iris_data.txt','r') \n",
    "text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file.read()    # Read complete information from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('iris_data.txt', sep=\",\", header=None, names=['Sepal.Length','Sepal.Width' ,'Petal.Length' ,'Petal.Width','Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ca02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "file = open('Test2.json')    # Full path to the json file, or simply the file name \n",
    "                               # if the firle is in your current working directory\n",
    "json_file = json.load(file)    # Returns JSON object as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73997430",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(json_file.items(), columns=['Information', 'Values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5860128",
   "metadata": {},
   "source": [
    "## Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a97659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2044aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Server = 'DESKTOP-22G7PV9'\n",
    "Database = 'Test'\n",
    "Driver = 'SQL Server'\n",
    "Database_Con = f'mssql://@{Server}/{Database}?driver={Driver}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac022285",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine=create_engine(Database_Con)\n",
    "con=engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_sql_query(\"Select * from[dbo].[Table_1]\",con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incert data into MS SQL Sever\n",
    "df =pd.read_csv('iris_data.txt', sep=\",\", header=None, names=['Sepal.Length','Sepal.Width' ,'Petal.Length' ,'Petal.Width','Species'])\n",
    "\n",
    "\n",
    "#Using sqlalchemy to enter data in MS Sql server (much easier)\n",
    "\n",
    "df.to_sql('Table_NameRt', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close() #close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc926f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_NAME = 'DESKTOP-22G7PV9'\n",
    "DATABASE_NAME = 'Test'\n",
    "USERNAME = 'DESKTOP-22G7PV9\\DELL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn= pyodbc.connect('Driver={SQL Server};' 'Server=DESKTOP-22G7PV9;' 'Database=Test;' 'Trusted_connection=yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36063277",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c421643",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM Table_1\"\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter new data\n",
    "cursor.execute('''\n",
    "                INSERT INTO Table_1 (F_Name, L_Name, Wages)\n",
    "                VALUES\n",
    "                ('Ti','Chair',150)\n",
    "                ''')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets verify here using Pandas\n",
    "import pandas as pd\n",
    "df=pd.read_sql_query(\"Select * from[dbo].[Table_1]\",conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close() #close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671e477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc89bd2",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5c5c5",
   "metadata": {},
   "source": [
    "Data wrangling is the process of transforming raw data into a more structured format.  \n",
    "organizing data by numerical data rather than categorical values or organizing\n",
    "data in tables rather than columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759d07a",
   "metadata": {},
   "source": [
    "We will  use Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e953b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data1 = {\n",
    "        'id': ['1', '2', '3', '4', '5'],\n",
    "        'Feature1': ['A', 'C', 'E', 'G', 'I'],\n",
    "        'Feature2': ['B', 'D', 'F', 'H', 'J']}\n",
    "\n",
    "df1 = pd.DataFrame(dummy_data1, columns = ['id', 'Feature1', 'Feature2'])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data2 = {\n",
    "        'id': ['1', '2', '6', '7', '8'],\n",
    "        'Feature3': ['K', 'M', 'O', 'Q', 'S'],\n",
    "        'Feature4': ['L', 'N', 'P', 'R', 'T']}\n",
    "\n",
    "df2 = pd.DataFrame(dummy_data2, columns = ['id', 'Feature3', 'Feature4'])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb1c28",
   "metadata": {},
   "source": [
    "# Concat\n",
    "\n",
    "Concatenate pandas objects along a particular axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af320f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_concat = pd.concat([df1, df2])\n",
    "row_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter at the 0 index\n",
    "\n",
    "row_concat.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for positional indexing - below is an example of getting the first observation\n",
    "\n",
    "row_concat.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the index for use\n",
    "\n",
    "row_concat_reset = pd.concat([df1, df2], ignore_index=True)\n",
    "row_concat_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8269dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_concat_reset['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a22d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f55ff776",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be5766",
   "metadata": {},
   "source": [
    "Similar to a database’s join operations. It’s the most flexible operations of combining tables.\n",
    "Use its when you want to combine data objects based on one or more keys, most useful \n",
    "when you want to combine rows that share data.\n",
    "\n",
    "You can achieve both many-to-one and many-to-many joins with merge().\n",
    "*this can cause duplicates in your data\n",
    "\n",
    "Types of merge:\n",
    "\n",
    "-inner\n",
    "-outer\n",
    "-left\n",
    "-right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner join\n",
    "\n",
    "inner= pd.merge(df1,df2, on=[\"id\"])\n",
    "inner\n",
    "inner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outer Join\n",
    "\n",
    "outer= pd.merge(df1,df2, how=\"outer\", on=[\"id\"])\n",
    "outer\n",
    "outer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left Join\n",
    "left = pd.merge(df1,df2,  how=\"left\", on=[\"id\"])\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#right Join\n",
    "right= pd.merge(df1,df2,  how=\"right\", on=[\"id\"])\n",
    "right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa21312",
   "metadata": {},
   "source": [
    "# Converting data types in dataframes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all columns to string type\n",
    "df1 = df1.astype(str)\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59093e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dataframe\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'C': [1.1, '1.0', '1.3', 2, 5]})\n",
    " \n",
    "# using dictionary to convert specific columns\n",
    "convert_dict = {'A': int,\n",
    "                'C': float\n",
    "                }\n",
    " \n",
    "df = df.astype(convert_dict)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes\n",
    "# using apply method\n",
    "df1[['id']] = df1[['id']].apply(pd.to_numeric)\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fb3ae",
   "metadata": {},
   "source": [
    "# Create a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085eefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lambda\n",
    "\n",
    "df1=df1.assign(id2 = lambda x: (x['id']+1))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ec116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.assign(nid=lambda row: row.id * 1.5)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['brand_new']= df1['id2']+df1['nid']\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a4c8c",
   "metadata": {},
   "source": [
    "# Subset or drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column\n",
    "\n",
    "del df1['brand_new']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns=['id2', 'nid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93bd3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset\n",
    "#subset based on a condition\n",
    "\n",
    "# subset of dataframe\n",
    "above_2 = df1[df1[\"id\"] > 2]\n",
    "above_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ca2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the index\n",
    "\n",
    "# Select rows 0, 1, 2 (row 3 is not selected)\n",
    "df1[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92043111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 5 rows (rows 0, 1, 2, 3, 4)\n",
    "df1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for iloc indexing to finding a specific data element\n",
    "#dat.iloc[row, column]\n",
    "\n",
    "df1.iloc[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.id == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d444a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f28125b",
   "metadata": {},
   "source": [
    "# Transposing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdf6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the melt function in Pandas  -  changes data table from wide to long or long to wide\n",
    "\n",
    "#syntax\n",
    "#DataFrame.melt(id_vars=None, value_vars=None, var_name=None, \n",
    "#               value_name='value', col_level=None, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\"Name\": [\"Pankaj\", \"Lisa\", \"David\"], \"ID\": [1, 2, 3], \"Role\": [\"CEO\", \"Editor\", \"Author\"]}\n",
    "\n",
    "df = pd.DataFrame(d1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df_melted = pd.melt(df, id_vars=[\"ID\"], value_vars=[\"Name\", \"Role\"])\n",
    "\n",
    "print(df_melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7de8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple columns as id\n",
    "\n",
    "df_melted = pd.melt(df, id_vars=[\"ID\", \"Name\"], value_vars=[\"Role\"])\n",
    "print(df_melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(df, id_vars=[\"Name\"], value_vars=[\"Role\"])\n",
    "print(df_melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmelt - get to the orginal dataframe\n",
    "d1 = {\"Name\": [\"Pankaj\", \"Lisa\", \"David\"], \"ID\": [1, 2, 3], \"Role\": [\"CEO\", \"Editor\", \"Author\"]}\n",
    "\n",
    "df = pd.DataFrame(d1)\n",
    "\n",
    "# print(df)\n",
    "\n",
    "df_melted = pd.melt(df, id_vars=[\"ID\"], value_vars=[\"Name\", \"Role\"], var_name=\"Attribute\", value_name=\"Value\")\n",
    "\n",
    "print(df_melted)\n",
    "\n",
    "# unmelting using pivot()\n",
    "\n",
    "df_unmelted = df_melted.pivot(index='ID', columns='Attribute')\n",
    "\n",
    "print(df_unmelted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d526da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in unmelete we need to reset the index\n",
    "\n",
    "df_unmelted = df_unmelted['Value'].reset_index()\n",
    "df_unmelted.columns.name = None\n",
    "print(df_unmelted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770011a3",
   "metadata": {},
   "source": [
    "# Exporting data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75f929",
   "metadata": {},
   "source": [
    "After we complete our work we may want to export our results in an external file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'C': [1.1, '1.0', '1.3', 2, 5]})\n",
    "\n",
    "df2.to_csv('F:\\YOUR DIRECTORY\\data.csv' , sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to Excel\n",
    "datatoexcel = pd.ExcelWriter('F:\\YOUR DIRECTORY\\CarsData1.xlsx')\n",
    " \n",
    "# write DataFrame to excel\n",
    "df2.to_excel(datatoexcel)\n",
    " \n",
    "# save the excel\n",
    "datatoexcel.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff47e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26858a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
